{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6066255,"sourceType":"datasetVersion","datasetId":3471819}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Task 1: BERT-based Customer Feedback Sentiment Classification\n# Install required libraries first (run in Kaggle notebook cell)\n\"\"\"\n!pip install transformers datasets torch scikit-learn matplotlib seaborn\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\nfrom torch.optim import AdamW\nfrom tqdm.auto import tqdm\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\ndef set_seed(seed=42):\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n\nset_seed(42)\n\n# Check device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# ============================================\n# STEP 1: Data Loading and Exploration\n# ============================================\n\n# Load the dataset\n# For Kaggle: Add the dataset to your notebook first\n# Path: /kaggle/input/customer-feedback-dataset/sentiment-analysis.csv\ndf = pd.read_csv('/kaggle/input/customer-feedback-dataset/sentiment-analysis.csv')\n\nprint(\"Dataset shape:\", df.shape)\nprint(\"\\nFirst few rows:\")\nprint(df.head())\nprint(\"\\nDataset info:\")\nprint(df.info())\nprint(\"\\nColumn names:\")\nprint(df.columns.tolist())\n\n# Check for missing values\nprint(\"\\nMissing values:\")\nprint(df.isnull().sum())\n\n# Display unique values in sentiment column\nif 'Sentiment' in df.columns:\n    print(\"\\nSentiment distribution:\")\n    print(df['Sentiment'].value_counts())\nelif 'sentiment' in df.columns:\n    print(\"\\nSentiment distribution:\")\n    print(df['sentiment'].value_counts())\n\n# ============================================\n# STEP 2: Data Preprocessing\n# ============================================\n\n# Adjust column names based on actual dataset\n# Common column names: ['text', 'sentiment'], ['feedback', 'sentiment'], ['review', 'label']\n# Let's handle multiple possibilities\n\ndef preprocess_dataframe(df):\n    \"\"\"Standardize dataframe columns\"\"\"\n    # Convert all column names to lowercase for consistency\n    df.columns = df.columns.str.lower()\n    \n    # Identify text column\n    text_cols = ['text', 'feedback', 'review', 'comment', 'message', 'opinion']\n    text_col = None\n    for col in text_cols:\n        if col in df.columns:\n            text_col = col\n            break\n    \n    # Identify sentiment column\n    sentiment_cols = ['sentiment', 'label', 'rating', 'emotion']\n    sentiment_col = None\n    for col in sentiment_cols:\n        if col in df.columns:\n            sentiment_col = col\n            break\n    \n    if text_col is None or sentiment_col is None:\n        print(\"Available columns:\", df.columns.tolist())\n        raise ValueError(\"Could not identify text or sentiment columns\")\n    \n    # Create standardized dataframe\n    processed_df = pd.DataFrame({\n        'text': df[text_col],\n        'sentiment': df[sentiment_col]\n    })\n    \n    return processed_df\n\ndf = preprocess_dataframe(df)\n\n# Remove duplicates\ndf = df.drop_duplicates()\n\n# Remove missing values\ndf = df.dropna()\n\n# Clean text data\ndef clean_text(text):\n    \"\"\"Basic text cleaning\"\"\"\n    if not isinstance(text, str):\n        text = str(text)\n    text = text.strip()\n    text = ' '.join(text.split())  # Remove extra whitespace\n    return text\n\ndf['text'] = df['text'].apply(clean_text)\n\n# Map sentiment labels to integers\n# Handle different sentiment formats\nunique_sentiments = df['sentiment'].unique()\nprint(f\"\\nUnique sentiments: {unique_sentiments}\")\n\n# Create label mapping\nif df['sentiment'].dtype == 'object':\n    # For string labels like 'positive', 'negative', 'neutral'\n    sentiment_mapping = {}\n    sentiment_names = []\n    \n    for idx, sentiment in enumerate(sorted(df['sentiment'].unique())):\n        sentiment_lower = str(sentiment).lower()\n        sentiment_mapping[sentiment] = idx\n        sentiment_names.append(sentiment_lower)\n    \n    df['label'] = df['sentiment'].map(sentiment_mapping)\nelse:\n    # For numeric labels\n    df['label'] = df['sentiment']\n    sentiment_names = [f\"class_{i}\" for i in sorted(df['label'].unique())]\n\nnum_labels = len(df['label'].unique())\nprint(f\"\\nNumber of classes: {num_labels}\")\nprint(f\"Label mapping: {sentiment_mapping if 'sentiment_mapping' in locals() else 'Using numeric labels'}\")\n\n# Visualize class distribution\nplt.figure(figsize=(10, 5))\ndf['label'].value_counts().plot(kind='bar')\nplt.title('Sentiment Distribution')\nplt.xlabel('Sentiment Label')\nplt.ylabel('Count')\nplt.xticks(rotation=0)\nplt.tight_layout()\nplt.savefig('sentiment_distribution.png', dpi=300, bbox_inches='tight')\nplt.show()\n\nprint(f\"\\nFinal dataset shape: {df.shape}\")\nprint(\"\\nClass distribution:\")\nprint(df['label'].value_counts())\nprint(\"\\nSample texts:\")\nprint(df.head(10))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === BERT training + evaluation cell ===\nimport os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer\n\nPRETRAINED = \"bert-base-uncased\"\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(PRETRAINED, use_fast=True)\n    print(\"Loaded tokenizer:\", PRETRAINED)\nexcept Exception as e:\n    print(\"AutoTokenizer load failed:\", e)\n    raise\n\nfrom tqdm.auto import tqdm\nimport seaborn as sns\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(\"Device:\", device)\n\n# Load processed DataFrame if not in memory\ntry:\n    processed\nexcept NameError:\n    processed = pd.read_csv('processed_sentiment.csv')\n    print(\"Loaded processed_sentiment.csv\")\n\n# Ensure columns: text, label\nassert 'text' in processed.columns and 'label' in processed.columns, \"processed must have 'text' and 'label' columns\"\n\n# --- Hyperparameters ---\nPRETRAINED = \"bert-base-uncased\"   # change if you prefer another model\nMAX_LEN = 128\nBATCH_SIZE = 16\nEPOCHS = 3\nLR = 2e-5\nWEIGHT_DECAY = 0.01\nSEED = 42\n\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\n# Train/Val split (stratify to keep class balance)\ntrain_df, val_df = train_test_split(processed, test_size=0.15, stratify=processed['label'], random_state=SEED)\ntrain_df = train_df.reset_index(drop=True)\nval_df = val_df.reset_index(drop=True)\nnum_labels = int(processed['label'].nunique())\nprint(f\"Train shape: {train_df.shape}, Val shape: {val_df.shape}, num_labels: {num_labels}\")\n\n# --- Tokenizer ---\ntokenizer = BertTokenizer.from_pretrained(PRETRAINED)\n\n# --- Dataset class ---\nclass FeedbackDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len=128):\n        self.texts = texts.tolist()\n        self.labels = labels.tolist()\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = str(self.texts[idx])\n        label = int(self.labels[idx])\n        encoding = self.tokenizer(\n            text,\n            add_special_tokens=True,\n            truncation=True,\n            max_length=self.max_len,\n            padding='max_length',\n            return_attention_mask=True,\n            return_tensors='pt'\n        )\n        item = {k: v.squeeze(0) for k, v in encoding.items()}\n        item['labels'] = torch.tensor(label, dtype=torch.long)\n        return item\n\n# --- DataLoaders ---\ntrain_dataset = FeedbackDataset(train_df['text'], train_df['label'], tokenizer, max_len=MAX_LEN)\nval_dataset = FeedbackDataset(val_df['text'], val_df['label'], tokenizer, max_len=MAX_LEN)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n\n# --- Model ---\nmodel = BertForSequenceClassification.from_pretrained(PRETRAINED, num_labels=num_labels)\nmodel.to(device)\n\n# --- Optimizer & Scheduler ---\noptimizer = AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\ntotal_steps = len(train_loader) * EPOCHS\nwarmup_steps = int(0.06 * total_steps)  # small warmup\nscheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=warmup_steps, num_training_steps=total_steps)\n\n# --- Training loop with validation ---\ndef train_epoch(model, dataloader, optimizer, scheduler, device):\n    model.train()\n    losses = []\n    preds = []\n    targets = []\n    loop = tqdm(dataloader, leave=False)\n    for batch in loop:\n        optimizer.zero_grad()\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n        loss = outputs.loss\n        logits = outputs.logits\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n        losses.append(loss.item())\n        batch_preds = torch.argmax(logits, dim=1).detach().cpu().numpy()\n        preds.extend(batch_preds.tolist())\n        targets.extend(labels.detach().cpu().numpy().tolist())\n        loop.set_description(f\"Train loss: {np.mean(losses):.4f}\")\n    acc = accuracy_score(targets, preds)\n    f1 = f1_score(targets, preds, average='macro')\n    return np.mean(losses), acc, f1\n\ndef eval_epoch(model, dataloader, device):\n    model.eval()\n    losses = []\n    preds = []\n    targets = []\n    with torch.no_grad():\n        loop = tqdm(dataloader, leave=False)\n        for batch in loop:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            logits = outputs.logits\n            losses.append(loss.item())\n            batch_preds = torch.argmax(logits, dim=1).detach().cpu().numpy()\n            preds.extend(batch_preds.tolist())\n            targets.extend(labels.detach().cpu().numpy().tolist())\n            loop.set_description(f\"Val loss: {np.mean(losses):.4f}\")\n    acc = accuracy_score(targets, preds)\n    f1 = f1_score(targets, preds, average='macro')\n    return np.mean(losses), acc, f1, targets, preds\n\nhistory = {'train_loss': [], 'train_acc': [], 'train_f1': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n\nfor epoch in range(EPOCHS):\n    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n    train_loss, train_acc, train_f1 = train_epoch(model, train_loader, optimizer, scheduler, device)\n    val_loss, val_acc, val_f1, val_targets, val_preds = eval_epoch(model, val_loader, device)\n    print(f\"Train loss: {train_loss:.4f} | acc: {train_acc:.4f} | f1: {train_f1:.4f}\")\n    print(f\"Val   loss: {val_loss:.4f} | acc: {val_acc:.4f} | f1: {val_f1:.4f}\")\n    history['train_loss'].append(train_loss)\n    history['train_acc'].append(train_acc)\n    history['train_f1'].append(train_f1)\n    history['val_loss'].append(val_loss)\n    history['val_acc'].append(val_acc)\n    history['val_f1'].append(val_f1)\n\n# --- Final evaluation & reporting ---\nprint(\"\\n=== Final Validation Report ===\")\nprint(classification_report(val_targets, val_preds, digits=4))\n\ncm = confusion_matrix(val_targets, val_preds)\nplt.figure(figsize=(6,5))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.title('Confusion Matrix (Validation)')\nplt.tight_layout()\nplt.savefig('confusion_matrix.png', dpi=300)\nplt.show()\n\n# Plot training curves\nplt.figure(figsize=(10,4))\nplt.subplot(1,2,1)\nplt.plot(history['train_loss'], label='train_loss')\nplt.plot(history['val_loss'], label='val_loss')\nplt.title('Loss')\nplt.legend()\nplt.subplot(1,2,2)\nplt.plot(history['train_f1'], label='train_f1')\nplt.plot(history['val_f1'], label='val_f1')\nplt.title('Macro F1')\nplt.legend()\nplt.tight_layout()\nplt.savefig('training_curves.png', dpi=300)\nplt.show()\n\n# Save model & tokenizer\nout_dir = \"bert_sentiment_model\"\nos.makedirs(out_dir, exist_ok=True)\nmodel.save_pretrained(out_dir)\ntokenizer.save_pretrained(out_dir)\nprint(f\"Saved model and tokenizer to {out_dir}\")\n\n# Save label mapping (if you created textual mapping)\nif 'sentiment_mapping' in locals():\n    import json\n    with open(os.path.join(out_dir, 'label_map.json'), 'w') as f:\n        json.dump(sentiment_mapping, f)\n    print(\"Saved label mapping to label_map.json\")\n\nprint(\"Done.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}